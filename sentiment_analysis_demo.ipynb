{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is a python library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "# numpy is a python library that supports multidimensional array and matrix manipulation\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from the csv into a dataframe\n",
    "df = pd.read_csv('word_sentiments.csv')\n",
    "# Drop unnecessary column (need inplace otherwise it doesn't save the changes to df)\n",
    "df.drop('Unnamed: 0', axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>had</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  score\n",
       "0    is  0.125\n",
       "1   not -0.625\n",
       "2  will  0.125\n",
       "3    an -0.125\n",
       "4   had  0.250"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what the first 5 rows of our dataframe looks like\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# load the word embeddings into the model from file\n",
    "filename = 'word2vecSmall.bin.gz'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "\n",
    "# Add column for word embeddings to dataframe\n",
    "# lambda functions are functions without names - what this is essentially saying is to go through\n",
    "# every word in our dataframe and access its word embedding from the model\n",
    "df['embedding'] = df['word'].apply(lambda x: model[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the words we want to test our model with - feel free to change these!\n",
    "# Ask audience to give us these words\n",
    "test_words = ['nice', 'mean', 'bad', 'good', 'sad', 'happy', 'fantastic', 'terrible']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>good</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>bad</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>[0.06298828, 0.12451172, 0.11328125, 0.0732421...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[-0.0005187988, 0.16015625, 0.0016098022, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Good</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[-0.10888672, -0.07470703, -0.045410156, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>fantastic</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[-0.122558594, -0.037841797, -0.12402344, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>sad</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[0.18945312, 0.045898438, 0.06689453, -0.04467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>terrible</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[0.1640625, 0.19238281, 0.092285156, 0.1308593...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>Bad</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>[-0.078125, -0.11279297, 0.018676758, 0.080566...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[0.05078125, -0.109375, -0.12597656, 0.1240234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[-0.34179688, -0.41015625, 0.45117188, -0.2871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>Fantastic</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[-0.064453125, -0.079589844, -0.17675781, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6365</th>\n",
       "      <td>Sad</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[0.22851562, -0.04663086, 0.11230469, -0.00616...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7451</th>\n",
       "      <td>SAD</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[-0.017211914, -0.23046875, -0.04345703, 0.062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>Terrible</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[0.296875, -0.06640625, 0.18457031, 0.00148773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11202</th>\n",
       "      <td>BAD</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>[-0.11035156, -0.12060547, 0.29101562, 0.13183...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  score                                          embedding\n",
       "16          good  0.500  [0.040527344, 0.0625, -0.017456055, 0.07861328...\n",
       "106          bad -0.875  [0.06298828, 0.12451172, 0.11328125, 0.0732421...\n",
       "164        happy  0.875  [-0.0005187988, 0.16015625, 0.0016098022, 0.02...\n",
       "649         Good  0.500  [-0.10888672, -0.07470703, -0.045410156, -0.00...\n",
       "717    fantastic  0.375  [-0.122558594, -0.037841797, -0.12402344, 0.02...\n",
       "750          sad -0.625  [0.18945312, 0.045898438, 0.06689453, -0.04467...\n",
       "907     terrible -0.625  [0.1640625, 0.19238281, 0.092285156, 0.1308593...\n",
       "1833         Bad -0.875  [-0.078125, -0.11279297, 0.018676758, 0.080566...\n",
       "2288       Happy  0.875  [0.05078125, -0.109375, -0.12597656, 0.1240234...\n",
       "2638        GOOD  0.500  [-0.34179688, -0.41015625, 0.45117188, -0.2871...\n",
       "6279   Fantastic  0.375  [-0.064453125, -0.079589844, -0.17675781, 0.00...\n",
       "6365         Sad -0.625  [0.22851562, -0.04663086, 0.11230469, -0.00616...\n",
       "7451         SAD -0.625  [-0.017211914, -0.23046875, -0.04345703, 0.062...\n",
       "8063    Terrible -0.625  [0.296875, -0.06640625, 0.18457031, 0.00148773...\n",
       "11202        BAD -0.875  [-0.11035156, -0.12060547, 0.29101562, 0.13183..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the data we are testing our model on (contains words in blacklist)\n",
    "# This is selecting all the rows in the dataframe whose rows are in the list of test words above, ignoring\n",
    "# uppercase/lowercase.\n",
    "test_df = df[df['word'].str.lower().str.strip().isin(test_words)].copy()\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[0.0070495605, -0.07324219, 0.171875, 0.022583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[0.08496094, -0.095214844, 0.119140625, 0.1118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[0.048828125, 0.16699219, 0.16894531, 0.087402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>[0.12597656, 0.19042969, 0.06982422, 0.0722656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>had</td>\n",
       "      <td>0.250</td>\n",
       "      <td>[-0.05810547, 0.05810547, 0.013305664, -0.0003...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  score                                          embedding\n",
       "0    is  0.125  [0.0070495605, -0.07324219, 0.171875, 0.022583...\n",
       "1   not -0.625  [0.08496094, -0.095214844, 0.119140625, 0.1118...\n",
       "2  will  0.125  [0.048828125, 0.16699219, 0.16894531, 0.087402...\n",
       "3    an -0.125  [0.12597656, 0.19042969, 0.06982422, 0.0722656...\n",
       "4   had  0.250  [-0.05810547, 0.05810547, 0.013305664, -0.0003..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the data we are training our model on (words NOT in blacklist - that's what the tilda does)\n",
    "train_df = df[~df['word'].str.lower().str.strip().isin(test_words)].copy()\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures input to LinearRegression model is in acceptable format\n",
    "# stack the word embeddings into a matrix of size (# words, len word embedding)\n",
    "X_train = np.stack(train_df['embedding'])\n",
    "\n",
    "# get sentiment scores of training words\n",
    "Y_train = train_df['score'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13510, 300)\n",
      "(13510,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.stack(test_df['embedding'])\n",
    "Y_test = test_df['score'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 300)\n",
      "(15,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to import model from sci-kit-learn, a popular python machine learning library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "classifier = LinearRegression()\n",
    "\n",
    "# Training step that Jason discussed - find optimal coefficients m1, m2, ... m300\n",
    "# and intercept b for all elements in word embedding to predict the sentiment score.\n",
    "classifier.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04330287,  0.03325967,  0.03816696,  0.04843961,  0.07981406,\n",
       "       -0.06076173,  0.01017331,  0.04856687, -0.00135716, -0.07473864,\n",
       "       -0.03097415, -0.04675719,  0.0262326 ,  0.05185932,  0.0490732 ,\n",
       "       -0.00244857,  0.02835969,  0.00132706, -0.03190776,  0.04603943,\n",
       "        0.00556938, -0.00254063, -0.02255786,  0.03554244,  0.04884313,\n",
       "       -0.01828668, -0.04620603,  0.01534572, -0.02309323,  0.01346445,\n",
       "        0.03423472, -0.00210104, -0.03097966,  0.0007009 ,  0.0912795 ,\n",
       "       -0.01944929, -0.02661762, -0.00465296,  0.04830752, -0.03746604,\n",
       "        0.02412963,  0.04419665, -0.03330516,  0.0063473 ,  0.02287202,\n",
       "       -0.02392988, -0.00519567,  0.00932641,  0.03537469,  0.00642737,\n",
       "        0.04289673,  0.0192745 ,  0.05949803,  0.00900436, -0.02819826,\n",
       "        0.02409115,  0.02673918, -0.0018694 , -0.01616765, -0.04826446,\n",
       "        0.03122853, -0.02812627, -0.03289875,  0.0426879 ,  0.02761098,\n",
       "        0.08378344, -0.03968249,  0.01112152,  0.06402335, -0.025371  ,\n",
       "        0.03420456,  0.0210727 ,  0.10403999,  0.02201968, -0.0098497 ,\n",
       "        0.01775159, -0.00567206,  0.07553939,  0.05006292, -0.01263243,\n",
       "       -0.00890417,  0.01253635,  0.11890255,  0.01492313, -0.04867652,\n",
       "        0.02479372,  0.01946771, -0.02783144, -0.01211391,  0.0166245 ,\n",
       "       -0.02410084,  0.04618608,  0.004281  , -0.02658918,  0.01157501,\n",
       "       -0.01536102, -0.06767817, -0.05682615, -0.00956699, -0.01785798,\n",
       "       -0.05545333,  0.01598024, -0.02102769,  0.02582768,  0.00193147,\n",
       "        0.00345356, -0.09635253, -0.00783372, -0.03190567, -0.0037794 ,\n",
       "        0.00749679,  0.06113141, -0.03212456,  0.01604684,  0.00188494,\n",
       "       -0.00219601, -0.01716195, -0.05374964,  0.03011227, -0.06871293,\n",
       "        0.05152545,  0.0191553 ,  0.00910285, -0.03028544,  0.00127538,\n",
       "        0.08032107,  0.00114038, -0.00650718, -0.00871253,  0.06525232,\n",
       "        0.00409469, -0.06503481,  0.04918464, -0.03402876,  0.02406273,\n",
       "        0.04832604,  0.03253467,  0.01484992,  0.02827195,  0.08158131,\n",
       "       -0.0542999 , -0.01313912, -0.01479594, -0.04846227, -0.02371661,\n",
       "        0.07465217,  0.07339028,  0.00211808,  0.07802992,  0.0113934 ,\n",
       "       -0.09337424, -0.01033183, -0.02533241, -0.04936294, -0.02160798,\n",
       "       -0.00700884,  0.05816523,  0.03272097,  0.01112356, -0.0506334 ,\n",
       "        0.04603112,  0.00952302,  0.04636019,  0.04202745, -0.04870538,\n",
       "       -0.01131514, -0.0131904 ,  0.00852121, -0.07450764,  0.02939915,\n",
       "       -0.05192618, -0.04123414,  0.02936687, -0.01295529,  0.01683892,\n",
       "        0.08271527, -0.04213251, -0.00118477, -0.02621012, -0.02960246,\n",
       "       -0.03626826,  0.00845955,  0.05321925, -0.06835282, -0.04564739,\n",
       "        0.01923833, -0.04724234, -0.0450337 , -0.015978  , -0.04959068,\n",
       "       -0.03383486,  0.05892045,  0.01932728, -0.06395695, -0.00881444,\n",
       "       -0.00407807, -0.00503716,  0.04969306,  0.03887832, -0.0472828 ,\n",
       "        0.0056608 , -0.01972761, -0.05504842, -0.00854516, -0.03842751,\n",
       "       -0.06448101, -0.01150313, -0.04737655,  0.04121467,  0.0325263 ,\n",
       "       -0.00420369,  0.02364339, -0.06281689,  0.05509018,  0.03576001,\n",
       "        0.03085981,  0.08418277,  0.05464295,  0.01783615,  0.13245504,\n",
       "        0.02696371,  0.0035351 ,  0.02683323, -0.03548747, -0.03608963,\n",
       "        0.01417712, -0.02343195, -0.0109537 , -0.01402779,  0.00871966,\n",
       "       -0.02692021, -0.00670836, -0.09366268, -0.01833383,  0.03780276,\n",
       "        0.00969778, -0.02054757,  0.08253169,  0.01019319, -0.01987832,\n",
       "       -0.08621104,  0.01907867, -0.0507396 ,  0.09137006, -0.0185417 ,\n",
       "        0.00082321, -0.02283264, -0.00702041,  0.03496121,  0.04670262,\n",
       "       -0.04654843,  0.00524765,  0.01476091,  0.00553685,  0.01736602,\n",
       "        0.01881735, -0.0893362 ,  0.04032025, -0.05056942,  0.01773396,\n",
       "        0.0500077 , -0.03774834, -0.06947742, -0.01670518,  0.02183631,\n",
       "       -0.00047196,  0.08825255, -0.05517648, -0.02332705,  0.0532268 ,\n",
       "       -0.00377484, -0.01102456, -0.01440395,  0.0390821 ,  0.00908643,\n",
       "       -0.0077878 ,  0.00834749, -0.03971649, -0.06325247,  0.00351564,\n",
       "       -0.02164049,  0.03231424,  0.01357478,  0.01748301,  0.02344109,\n",
       "        0.02716313, -0.01465506, -0.01032226,  0.08715558,  0.04192791,\n",
       "       -0.06231219, -0.04015128,  0.08014119, -0.02284065,  0.04607353,\n",
       "       -0.03450718,  0.05833263, -0.03703557, -0.04599959, -0.05249755],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the m1, m2, ..., m300 we wanted to find.\n",
    "classifier.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gets the shape of coefficients of the LinearRegression model, which we can see is the same\n",
    "# as the length of the embedding input.\n",
    "classifier.coef_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059657402"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the intercept of the LinearRegression model (the 'b' in y = mx + b)\n",
    "classifier.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5823370625581086\n"
     ]
    }
   ],
   "source": [
    "# Gets the r^2 coefficient - don't need to know nitty gritty of this, it just measures how\n",
    "# accurate our model is.\n",
    "# We want our r^2 to be above 0 (positive correlation between predicted sentiment scores and actual scores)\n",
    "# and as close to 1 as possible (that would mean perfect correlation).\n",
    "\n",
    "# 0.58 is pretty good!\n",
    "print(\"Score:\", classifier.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see this in action, let's get a word from our test set that obviously has a positive sentiment and\n",
    "# one with an obvious negative sentiment\n",
    "happy_vector = [np.array(model['happy'])]\n",
    "sad_vector = [np.array(model['sad'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27819216]\n",
      "[-0.23761618]\n"
     ]
    }
   ],
   "source": [
    "# Here's an example of output from the model - 'happy' should have a higher sentiment score than 'sad'\n",
    "print(classifier.predict(happy_vector))\n",
    "print(classifier.predict(sad_vector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It would help us humans understand what's going on better if we had a way to visualize these predictions.\n",
    "# pandas has some pretty nice built in plotting features - we're going to put the predicted scores\n",
    "# into the dataframe so pandas can plot it for us.\n",
    "#\n",
    "# We can create a new column called predicted_score and set it equal to the classifier's output for the X_test\n",
    "# matrix we made above.\n",
    "test_df['predicted_score'] = classifier.predict(X_test)\n",
    "\n",
    "# To make our plot prettier let's sort by predicted scores, so bars will be displayed in order of \n",
    "# lowest to highest predicted sentiment\n",
    "test_df.sort_values(by=['predicted_score'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>terrible</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[0.1640625, 0.19238281, 0.092285156, 0.1308593...</td>\n",
       "      <td>-0.473126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>bad</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>[0.06298828, 0.12451172, 0.11328125, 0.0732421...</td>\n",
       "      <td>-0.370561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>Terrible</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[0.296875, -0.06640625, 0.18457031, 0.00148773...</td>\n",
       "      <td>-0.345227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>Bad</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>[-0.078125, -0.11279297, 0.018676758, 0.080566...</td>\n",
       "      <td>-0.327850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7451</th>\n",
       "      <td>SAD</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[-0.017211914, -0.23046875, -0.04345703, 0.062...</td>\n",
       "      <td>-0.237694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>sad</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[0.18945312, 0.045898438, 0.06689453, -0.04467...</td>\n",
       "      <td>-0.237616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11202</th>\n",
       "      <td>BAD</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>[-0.11035156, -0.12060547, 0.29101562, 0.13183...</td>\n",
       "      <td>-0.216126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6365</th>\n",
       "      <td>Sad</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>[0.22851562, -0.04663086, 0.11230469, -0.00616...</td>\n",
       "      <td>-0.173545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>Fantastic</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[-0.064453125, -0.079589844, -0.17675781, 0.00...</td>\n",
       "      <td>-0.006199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[-0.34179688, -0.41015625, 0.45117188, -0.2871...</td>\n",
       "      <td>0.113062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>good</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "      <td>0.160842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>fantastic</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[-0.122558594, -0.037841797, -0.12402344, 0.02...</td>\n",
       "      <td>0.186539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Good</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[-0.10888672, -0.07470703, -0.045410156, -0.00...</td>\n",
       "      <td>0.204315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[-0.0005187988, 0.16015625, 0.0016098022, 0.02...</td>\n",
       "      <td>0.278192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[0.05078125, -0.109375, -0.12597656, 0.1240234...</td>\n",
       "      <td>0.348030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  score                                          embedding  \\\n",
       "907     terrible -0.625  [0.1640625, 0.19238281, 0.092285156, 0.1308593...   \n",
       "106          bad -0.875  [0.06298828, 0.12451172, 0.11328125, 0.0732421...   \n",
       "8063    Terrible -0.625  [0.296875, -0.06640625, 0.18457031, 0.00148773...   \n",
       "1833         Bad -0.875  [-0.078125, -0.11279297, 0.018676758, 0.080566...   \n",
       "7451         SAD -0.625  [-0.017211914, -0.23046875, -0.04345703, 0.062...   \n",
       "750          sad -0.625  [0.18945312, 0.045898438, 0.06689453, -0.04467...   \n",
       "11202        BAD -0.875  [-0.11035156, -0.12060547, 0.29101562, 0.13183...   \n",
       "6365         Sad -0.625  [0.22851562, -0.04663086, 0.11230469, -0.00616...   \n",
       "6279   Fantastic  0.375  [-0.064453125, -0.079589844, -0.17675781, 0.00...   \n",
       "2638        GOOD  0.500  [-0.34179688, -0.41015625, 0.45117188, -0.2871...   \n",
       "16          good  0.500  [0.040527344, 0.0625, -0.017456055, 0.07861328...   \n",
       "717    fantastic  0.375  [-0.122558594, -0.037841797, -0.12402344, 0.02...   \n",
       "649         Good  0.500  [-0.10888672, -0.07470703, -0.045410156, -0.00...   \n",
       "164        happy  0.875  [-0.0005187988, 0.16015625, 0.0016098022, 0.02...   \n",
       "2288       Happy  0.875  [0.05078125, -0.109375, -0.12597656, 0.1240234...   \n",
       "\n",
       "       predicted_score  \n",
       "907          -0.473126  \n",
       "106          -0.370561  \n",
       "8063         -0.345227  \n",
       "1833         -0.327850  \n",
       "7451         -0.237694  \n",
       "750          -0.237616  \n",
       "11202        -0.216126  \n",
       "6365         -0.173545  \n",
       "6279         -0.006199  \n",
       "2638          0.113062  \n",
       "16            0.160842  \n",
       "717           0.186539  \n",
       "649           0.204315  \n",
       "164           0.278192  \n",
       "2288          0.348030  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now see the new column we've added into the dataframe.\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12e7f1240>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A bar plot showing what our model thinks the sentiments of our test words are and what they actually are\n",
    "# Doesn't get the magnitude of positive or negative sentiment that well, but it gets the general idea!\n",
    "test_df.plot.bar(x='word',y=['predicted_score', 'score'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
