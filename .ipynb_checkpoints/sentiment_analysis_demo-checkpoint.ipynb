{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "filename = 'word2vecSmall.bin.gz'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/jackieoh/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jackieoh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "import numpy as np\n",
    "\n",
    "sentiment_scores = {}\n",
    "\n",
    "for word in model.vocab:\n",
    "    score = list(swn.senti_synsets(word))\n",
    "    if score:\n",
    "        compound_score = score[0].pos_score() - score[0].neg_score()\n",
    "        if compound_score != 0:\n",
    "            sentiment_scores[word] = compound_score\n",
    "\n",
    "words_to_word_embeddings = []\n",
    "\n",
    "for word in sentiment_scores.keys():\n",
    "    words_to_word_embeddings.append([word, np.array(model[word]), sentiment_scores[word]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(words_to_word_embeddings, columns=['word', 'embedding', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the words we want to test our model with \n",
    "blacklist = ['nice', 'mean', 'bad', 'good', 'sad', 'happy', 'fantastic', 'terrible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>embedding</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>good</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>bad</td>\n",
       "      <td>[0.06298828, 0.12451172, 0.11328125, 0.0732421...</td>\n",
       "      <td>-0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>happy</td>\n",
       "      <td>[-0.0005187988, 0.16015625, 0.0016098022, 0.02...</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Good</td>\n",
       "      <td>[-0.10888672, -0.07470703, -0.045410156, -0.00...</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>fantastic</td>\n",
       "      <td>[-0.122558594, -0.037841797, -0.12402344, 0.02...</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>sad</td>\n",
       "      <td>[0.18945312, 0.045898438, 0.06689453, -0.04467...</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>terrible</td>\n",
       "      <td>[0.1640625, 0.19238281, 0.092285156, 0.1308593...</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>Bad</td>\n",
       "      <td>[-0.078125, -0.11279297, 0.018676758, 0.080566...</td>\n",
       "      <td>-0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>Happy</td>\n",
       "      <td>[0.05078125, -0.109375, -0.12597656, 0.1240234...</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>[-0.34179688, -0.41015625, 0.45117188, -0.2871...</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>Fantastic</td>\n",
       "      <td>[-0.064453125, -0.079589844, -0.17675781, 0.00...</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6365</th>\n",
       "      <td>Sad</td>\n",
       "      <td>[0.22851562, -0.04663086, 0.11230469, -0.00616...</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7451</th>\n",
       "      <td>SAD</td>\n",
       "      <td>[-0.017211914, -0.23046875, -0.04345703, 0.062...</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>Terrible</td>\n",
       "      <td>[0.296875, -0.06640625, 0.18457031, 0.00148773...</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11202</th>\n",
       "      <td>BAD</td>\n",
       "      <td>[-0.11035156, -0.12060547, 0.29101562, 0.13183...</td>\n",
       "      <td>-0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word                                          embedding  score\n",
       "16          good  [0.040527344, 0.0625, -0.017456055, 0.07861328...  0.500\n",
       "106          bad  [0.06298828, 0.12451172, 0.11328125, 0.0732421... -0.875\n",
       "164        happy  [-0.0005187988, 0.16015625, 0.0016098022, 0.02...  0.875\n",
       "649         Good  [-0.10888672, -0.07470703, -0.045410156, -0.00...  0.500\n",
       "717    fantastic  [-0.122558594, -0.037841797, -0.12402344, 0.02...  0.375\n",
       "750          sad  [0.18945312, 0.045898438, 0.06689453, -0.04467... -0.625\n",
       "907     terrible  [0.1640625, 0.19238281, 0.092285156, 0.1308593... -0.625\n",
       "1833         Bad  [-0.078125, -0.11279297, 0.018676758, 0.080566... -0.875\n",
       "2288       Happy  [0.05078125, -0.109375, -0.12597656, 0.1240234...  0.875\n",
       "2638        GOOD  [-0.34179688, -0.41015625, 0.45117188, -0.2871...  0.500\n",
       "6279   Fantastic  [-0.064453125, -0.079589844, -0.17675781, 0.00...  0.375\n",
       "6365         Sad  [0.22851562, -0.04663086, 0.11230469, -0.00616... -0.625\n",
       "7451         SAD  [-0.017211914, -0.23046875, -0.04345703, 0.062... -0.625\n",
       "8063    Terrible  [0.296875, -0.06640625, 0.18457031, 0.00148773... -0.625\n",
       "11202        BAD  [-0.11035156, -0.12060547, 0.29101562, 0.13183... -0.875"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the \n",
    "test_df = df[df['word'].str.lower().str.strip().isin(blacklist)]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>embedding</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is</td>\n",
       "      <td>[0.0070495605, -0.07324219, 0.171875, 0.022583...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not</td>\n",
       "      <td>[0.08496094, -0.095214844, 0.119140625, 0.1118...</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will</td>\n",
       "      <td>[0.048828125, 0.16699219, 0.16894531, 0.087402...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an</td>\n",
       "      <td>[0.12597656, 0.19042969, 0.06982422, 0.0722656...</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>had</td>\n",
       "      <td>[-0.05810547, 0.05810547, 0.013305664, -0.0003...</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>were</td>\n",
       "      <td>[-0.10058594, -0.024658203, 0.092285156, -0.04...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>been</td>\n",
       "      <td>[-0.10107422, 0.017700195, 0.014709473, 0.0275...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>new</td>\n",
       "      <td>[0.011291504, 0.028930664, 0.083496094, -0.049...</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>other</td>\n",
       "      <td>[-0.04248047, -0.08251953, 0.043945312, 0.1318...</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>just</td>\n",
       "      <td>[0.10107422, -0.0038146973, 0.018188477, 0.129...</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>no</td>\n",
       "      <td>[0.08251953, -0.15136719, 0.06591797, 0.020019...</td>\n",
       "      <td>-0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>like</td>\n",
       "      <td>[0.103515625, 0.13769531, -0.0029754639, 0.181...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>off</td>\n",
       "      <td>[-0.071777344, -0.11035156, 0.008239746, 0.151...</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>make</td>\n",
       "      <td>[-0.11328125, -0.036865234, 0.09423828, 0.0079...</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>says</td>\n",
       "      <td>[0.043701172, -0.11425781, 0.06738281, -0.0605...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>down</td>\n",
       "      <td>[0.024536133, -0.10498047, 0.26171875, 0.18554...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>such</td>\n",
       "      <td>[0.060791016, -0.013793945, 0.021728516, 0.091...</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>very</td>\n",
       "      <td>[0.016601562, 0.045654297, -0.119140625, 0.069...</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>high</td>\n",
       "      <td>[0.076660156, 0.00970459, -0.080078125, 0.1816...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>then</td>\n",
       "      <td>[0.044677734, -0.007232666, 0.115234375, 0.131...</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>say</td>\n",
       "      <td>[-0.036132812, -0.12109375, 0.13378906, 0.1142...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>help</td>\n",
       "      <td>[0.049804688, 0.06640625, 0.038330078, 0.02355...</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>know</td>\n",
       "      <td>[-0.05493164, -0.1171875, 0.027832031, 0.07470...</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>want</td>\n",
       "      <td>[0.13671875, 0.1484375, 0.114746094, 0.0698242...</td>\n",
       "      <td>-0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>got</td>\n",
       "      <td>[0.06201172, 0.10839844, -0.09667969, 0.079101...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>another</td>\n",
       "      <td>[0.19433594, -0.01965332, 0.091796875, 0.10449...</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>best</td>\n",
       "      <td>[-0.12695312, 0.021972656, 0.28710938, 0.15332...</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>win</td>\n",
       "      <td>[0.14941406, 0.06542969, -0.02722168, -0.12988...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>today</td>\n",
       "      <td>[-0.07470703, -0.05883789, 0.045654297, -0.129...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>set</td>\n",
       "      <td>[0.029541016, 0.25976562, 0.19335938, 0.088378...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>assail</td>\n",
       "      <td>[0.076171875, 0.23242188, 0.05517578, 0.197265...</td>\n",
       "      <td>-0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>Believes</td>\n",
       "      <td>[0.40625, 0.06933594, -0.1796875, 0.04736328, ...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>shyly</td>\n",
       "      <td>[0.17089844, -0.103515625, 0.083984375, 0.0612...</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>unheated</td>\n",
       "      <td>[-0.13476562, 0.23339844, 0.03491211, -0.11669...</td>\n",
       "      <td>-0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>letdowns</td>\n",
       "      <td>[0.001045227, 0.18164062, 0.048828125, 0.41210...</td>\n",
       "      <td>-0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13500</th>\n",
       "      <td>paperboard</td>\n",
       "      <td>[-0.07373047, -0.11767578, -0.48828125, 0.3222...</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501</th>\n",
       "      <td>mumble</td>\n",
       "      <td>[0.33007812, -0.25585938, 0.022827148, 0.29296...</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13502</th>\n",
       "      <td>DED</td>\n",
       "      <td>[-0.32421875, 0.21679688, -0.33789062, -0.2255...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13503</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>[-0.24902344, -0.18945312, -0.06738281, 0.0490...</td>\n",
       "      <td>-0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13504</th>\n",
       "      <td>deviates</td>\n",
       "      <td>[-0.118652344, -0.23632812, -0.16601562, 0.067...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13505</th>\n",
       "      <td>discordant</td>\n",
       "      <td>[-0.059570312, -0.12060547, -0.15039062, 0.111...</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13506</th>\n",
       "      <td>scoundrels</td>\n",
       "      <td>[0.059326172, 0.19921875, -0.21289062, 0.3125,...</td>\n",
       "      <td>-0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>canard</td>\n",
       "      <td>[0.43554688, 0.17578125, -0.014038086, 0.29687...</td>\n",
       "      <td>-0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13508</th>\n",
       "      <td>enraging</td>\n",
       "      <td>[0.2421875, 0.12060547, 0.1171875, -0.30273438...</td>\n",
       "      <td>-0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13509</th>\n",
       "      <td>haredi</td>\n",
       "      <td>[0.12158203, -0.24121094, -0.26171875, 0.12158...</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>Opponent</td>\n",
       "      <td>[0.25, -0.03955078, 0.3125, -0.078125, 0.00946...</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>alacrity</td>\n",
       "      <td>[0.28125, 0.16601562, -0.09375, 0.087890625, -...</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13512</th>\n",
       "      <td>smugly</td>\n",
       "      <td>[0.27734375, 0.06933594, -0.056396484, 0.27343...</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>dispels</td>\n",
       "      <td>[0.13476562, 0.265625, 0.059814453, -0.5546875...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>pester</td>\n",
       "      <td>[0.25195312, 0.1796875, 0.11767578, 0.02685546...</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>mightiest</td>\n",
       "      <td>[0.24316406, 0.15820312, 0.125, 0.33203125, -0...</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13516</th>\n",
       "      <td>claustrophobia</td>\n",
       "      <td>[0.23828125, -0.18554688, -0.37109375, 0.00236...</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517</th>\n",
       "      <td>Commemorative</td>\n",
       "      <td>[0.10253906, -0.07373047, -0.071777344, 0.1630...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13518</th>\n",
       "      <td>Clusters</td>\n",
       "      <td>[-0.08203125, 0.17675781, 0.09326172, 0.234375...</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13519</th>\n",
       "      <td>pronto</td>\n",
       "      <td>[-0.19140625, -0.12060547, 0.079589844, 0.0134...</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13520</th>\n",
       "      <td>entices</td>\n",
       "      <td>[0.32421875, 0.08886719, -0.060791016, -0.0742...</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13521</th>\n",
       "      <td>pet_peeve</td>\n",
       "      <td>[0.00075149536, -0.29492188, 0.24511719, 0.253...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13522</th>\n",
       "      <td>marring</td>\n",
       "      <td>[0.09716797, 0.24316406, 0.025146484, -0.07812...</td>\n",
       "      <td>-0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13523</th>\n",
       "      <td>fagot</td>\n",
       "      <td>[-0.123535156, -0.12207031, 0.5078125, 0.26562...</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13524</th>\n",
       "      <td>Tibetan_Buddhism</td>\n",
       "      <td>[0.31445312, 0.013305664, 0.5078125, 0.3105468...</td>\n",
       "      <td>-0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13510 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word                                          embedding  \\\n",
       "0                    is  [0.0070495605, -0.07324219, 0.171875, 0.022583...   \n",
       "1                   not  [0.08496094, -0.095214844, 0.119140625, 0.1118...   \n",
       "2                  will  [0.048828125, 0.16699219, 0.16894531, 0.087402...   \n",
       "3                    an  [0.12597656, 0.19042969, 0.06982422, 0.0722656...   \n",
       "4                   had  [-0.05810547, 0.05810547, 0.013305664, -0.0003...   \n",
       "5                  were  [-0.10058594, -0.024658203, 0.092285156, -0.04...   \n",
       "6                  been  [-0.10107422, 0.017700195, 0.014709473, 0.0275...   \n",
       "7                   new  [0.011291504, 0.028930664, 0.083496094, -0.049...   \n",
       "8                 other  [-0.04248047, -0.08251953, 0.043945312, 0.1318...   \n",
       "9                  just  [0.10107422, -0.0038146973, 0.018188477, 0.129...   \n",
       "10                   no  [0.08251953, -0.15136719, 0.06591797, 0.020019...   \n",
       "11                 like  [0.103515625, 0.13769531, -0.0029754639, 0.181...   \n",
       "12                  off  [-0.071777344, -0.11035156, 0.008239746, 0.151...   \n",
       "13                 make  [-0.11328125, -0.036865234, 0.09423828, 0.0079...   \n",
       "14                 says  [0.043701172, -0.11425781, 0.06738281, -0.0605...   \n",
       "15                 down  [0.024536133, -0.10498047, 0.26171875, 0.18554...   \n",
       "17                 such  [0.060791016, -0.013793945, 0.021728516, 0.091...   \n",
       "18                 very  [0.016601562, 0.045654297, -0.119140625, 0.069...   \n",
       "19                 high  [0.076660156, 0.00970459, -0.080078125, 0.1816...   \n",
       "20                 then  [0.044677734, -0.007232666, 0.115234375, 0.131...   \n",
       "21                  say  [-0.036132812, -0.12109375, 0.13378906, 0.1142...   \n",
       "22                 help  [0.049804688, 0.06640625, 0.038330078, 0.02355...   \n",
       "23                 know  [-0.05493164, -0.1171875, 0.027832031, 0.07470...   \n",
       "24                 want  [0.13671875, 0.1484375, 0.114746094, 0.0698242...   \n",
       "25                  got  [0.06201172, 0.10839844, -0.09667969, 0.079101...   \n",
       "26              another  [0.19433594, -0.01965332, 0.091796875, 0.10449...   \n",
       "27                 best  [-0.12695312, 0.021972656, 0.28710938, 0.15332...   \n",
       "28                  win  [0.14941406, 0.06542969, -0.02722168, -0.12988...   \n",
       "29                today  [-0.07470703, -0.05883789, 0.045654297, -0.129...   \n",
       "30                  set  [0.029541016, 0.25976562, 0.19335938, 0.088378...   \n",
       "...                 ...                                                ...   \n",
       "13495            assail  [0.076171875, 0.23242188, 0.05517578, 0.197265...   \n",
       "13496          Believes  [0.40625, 0.06933594, -0.1796875, 0.04736328, ...   \n",
       "13497             shyly  [0.17089844, -0.103515625, 0.083984375, 0.0612...   \n",
       "13498          unheated  [-0.13476562, 0.23339844, 0.03491211, -0.11669...   \n",
       "13499          letdowns  [0.001045227, 0.18164062, 0.048828125, 0.41210...   \n",
       "13500        paperboard  [-0.07373047, -0.11767578, -0.48828125, 0.3222...   \n",
       "13501            mumble  [0.33007812, -0.25585938, 0.022827148, 0.29296...   \n",
       "13502               DED  [-0.32421875, 0.21679688, -0.33789062, -0.2255...   \n",
       "13503           Abusive  [-0.24902344, -0.18945312, -0.06738281, 0.0490...   \n",
       "13504          deviates  [-0.118652344, -0.23632812, -0.16601562, 0.067...   \n",
       "13505        discordant  [-0.059570312, -0.12060547, -0.15039062, 0.111...   \n",
       "13506        scoundrels  [0.059326172, 0.19921875, -0.21289062, 0.3125,...   \n",
       "13507            canard  [0.43554688, 0.17578125, -0.014038086, 0.29687...   \n",
       "13508          enraging  [0.2421875, 0.12060547, 0.1171875, -0.30273438...   \n",
       "13509            haredi  [0.12158203, -0.24121094, -0.26171875, 0.12158...   \n",
       "13510          Opponent  [0.25, -0.03955078, 0.3125, -0.078125, 0.00946...   \n",
       "13511          alacrity  [0.28125, 0.16601562, -0.09375, 0.087890625, -...   \n",
       "13512            smugly  [0.27734375, 0.06933594, -0.056396484, 0.27343...   \n",
       "13513           dispels  [0.13476562, 0.265625, 0.059814453, -0.5546875...   \n",
       "13514            pester  [0.25195312, 0.1796875, 0.11767578, 0.02685546...   \n",
       "13515         mightiest  [0.24316406, 0.15820312, 0.125, 0.33203125, -0...   \n",
       "13516    claustrophobia  [0.23828125, -0.18554688, -0.37109375, 0.00236...   \n",
       "13517     Commemorative  [0.10253906, -0.07373047, -0.071777344, 0.1630...   \n",
       "13518          Clusters  [-0.08203125, 0.17675781, 0.09326172, 0.234375...   \n",
       "13519            pronto  [-0.19140625, -0.12060547, 0.079589844, 0.0134...   \n",
       "13520           entices  [0.32421875, 0.08886719, -0.060791016, -0.0742...   \n",
       "13521         pet_peeve  [0.00075149536, -0.29492188, 0.24511719, 0.253...   \n",
       "13522           marring  [0.09716797, 0.24316406, 0.025146484, -0.07812...   \n",
       "13523             fagot  [-0.123535156, -0.12207031, 0.5078125, 0.26562...   \n",
       "13524  Tibetan_Buddhism  [0.31445312, 0.013305664, 0.5078125, 0.3105468...   \n",
       "\n",
       "       score  \n",
       "0      0.125  \n",
       "1     -0.625  \n",
       "2      0.125  \n",
       "3     -0.125  \n",
       "4      0.250  \n",
       "5      0.125  \n",
       "6      0.125  \n",
       "7      0.375  \n",
       "8     -0.625  \n",
       "9      0.625  \n",
       "10    -0.250  \n",
       "11     0.125  \n",
       "12    -0.625  \n",
       "13     0.500  \n",
       "14     0.125  \n",
       "15     0.125  \n",
       "17    -0.125  \n",
       "18     0.500  \n",
       "19     0.125  \n",
       "20     0.375  \n",
       "21     0.125  \n",
       "22     0.500  \n",
       "23     0.625  \n",
       "24    -0.250  \n",
       "25     0.125  \n",
       "26    -0.125  \n",
       "27     0.250  \n",
       "28     0.125  \n",
       "29     0.125  \n",
       "30     0.125  \n",
       "...      ...  \n",
       "13495 -0.375  \n",
       "13496  0.125  \n",
       "13497  0.375  \n",
       "13498 -0.750  \n",
       "13499 -0.750  \n",
       "13500  0.750  \n",
       "13501 -0.125  \n",
       "13502  0.125  \n",
       "13503 -0.875  \n",
       "13504  0.125  \n",
       "13505 -0.625  \n",
       "13506 -0.375  \n",
       "13507 -0.875  \n",
       "13508 -0.750  \n",
       "13509 -0.625  \n",
       "13510 -0.125  \n",
       "13511  0.375  \n",
       "13512  0.375  \n",
       "13513  0.125  \n",
       "13514 -0.125  \n",
       "13515  0.375  \n",
       "13516 -0.125  \n",
       "13517  0.125  \n",
       "13518 -0.125  \n",
       "13519  0.375  \n",
       "13520 -0.125  \n",
       "13521  0.125  \n",
       "13522 -0.375  \n",
       "13523 -0.125  \n",
       "13524 -0.250  \n",
       "\n",
       "[13510 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df[~df['word'].str.lower().str.strip().isin(blacklist)]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "5         True\n",
       "6         True\n",
       "7         True\n",
       "8         True\n",
       "9         True\n",
       "10        True\n",
       "11        True\n",
       "12        True\n",
       "13        True\n",
       "14        True\n",
       "15        True\n",
       "16       False\n",
       "17        True\n",
       "18        True\n",
       "19        True\n",
       "20        True\n",
       "21        True\n",
       "22        True\n",
       "23        True\n",
       "24        True\n",
       "25        True\n",
       "26        True\n",
       "27        True\n",
       "28        True\n",
       "29        True\n",
       "         ...  \n",
       "13495     True\n",
       "13496     True\n",
       "13497     True\n",
       "13498     True\n",
       "13499     True\n",
       "13500     True\n",
       "13501     True\n",
       "13502     True\n",
       "13503     True\n",
       "13504     True\n",
       "13505     True\n",
       "13506     True\n",
       "13507     True\n",
       "13508     True\n",
       "13509     True\n",
       "13510     True\n",
       "13511     True\n",
       "13512     True\n",
       "13513     True\n",
       "13514     True\n",
       "13515     True\n",
       "13516     True\n",
       "13517     True\n",
       "13518     True\n",
       "13519     True\n",
       "13520     True\n",
       "13521     True\n",
       "13522     True\n",
       "13523     True\n",
       "13524     True\n",
       "Name: word, Length: 13525, dtype: bool"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~df['word'].str.lower().str.strip().isin(blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(np.array(list(df['embedding'].values)), np.array(df['score'].values), test_size=0.2)\n",
    "                                                    \n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13510, 300), (13510,))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(list(train_df['embedding'].values))\n",
    "X_test = np.array(list(train_df['score'].values))\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13510, 300)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearRegression()\n",
    "#classifier.fit(X_train, y_train)\n",
    "classifier.fit(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3181486154131491\n"
     ]
    }
   ],
   "source": [
    "print(\"Score:\", classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15140586], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict([np.array(model['rich'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.coef_.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
